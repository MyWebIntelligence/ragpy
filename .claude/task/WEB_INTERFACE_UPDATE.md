# Mise √† jour de l'interface web - Support CSV

**Date** : 2025-10-21
**Version** : 1.1
**Statut** : ‚úÖ Termin√©

---

## Vue d'ensemble

L'interface web RAGpy (FastAPI) a √©t√© mise √† jour pour supporter **deux modes d'ingestion** :
- **Option A** : ZIP Archive (Zotero + PDFs) - flux existant
- **Option B** : CSV File (texte direct) - **NOUVEAU**

---

## Changements apport√©s

### 1. Backend - Nouvelle route `/upload_csv`

**Fichier** : [app/main.py](app/main.py:143-215)

```python
@app.post("/upload_csv")
async def upload_csv_endpoint(file: UploadFile = File(...)):
    """
    Upload CSV file for direct ingestion (bypass PDF/OCR).
    Converts CSV to DataFrame using ingestion.csv_ingestion module,
    then saves it as output.csv for the pipeline.
    """
```

**Fonctionnement** :
1. Re√ßoit un fichier `.csv` upload√©
2. Valide l'extension (refuse les non-CSV)
3. Cr√©e un r√©pertoire unique dans `uploads/`
4. Appelle `ingest_csv_to_dataframe()` du module `ingestion`
5. Sauvegarde le DataFrame comme `output.csv` (compatible avec le pipeline)
6. Retourne le chemin de session pour les √©tapes suivantes

**R√©ponse** :
```json
{
  "path": "a1b2c3d4_my_documents",
  "tree": ["output.csv"],
  "message": "CSV ingested successfully: 42 rows processed."
}
```

---

### 2. Frontend - Interface double choix

**Fichier** : [app/templates/index.html](app/templates/index.html:131-163)

#### Avant (v1.0)

```html
<section id="upload-section">
  <h2>1. Upload ZIP Archive</h2>
  <form id="uploadForm" enctype="multipart/form-data">
    <input type="file" name="file" accept=".zip" required />
    <button type="submit">Upload</button>
  </form>
</section>
```

**Probl√®me** :
- Pas d'explication claire
- Accepte seulement ZIP
- CSV rejet√© avec erreur

#### Apr√®s (v1.1)

```html
<section id="upload-section">
  <h2>1. Upload Documents</h2>
  <p>Choose your data source:</p>

  <!-- Option A: ZIP (Zotero + PDFs) -->
  <div style="border: 2px solid #1976d2; ...">
    <h3>üì¶ Option A: ZIP Archive (Zotero + PDFs)</h3>
    <p>For Zotero exports... Requires OCR processing.</p>
    <form id="uploadZipForm">...</form>
  </div>

  <!-- Option B: CSV Direct -->
  <div style="border: 2px solid #2e7d32; ...">
    <h3>üìÑ Option B: CSV File (Direct Text)</h3>
    <p>For CSV files... Skips OCR - faster and cheaper.</p>
    <form id="uploadCsvForm">...</form>
  </div>
</section>
```

**Am√©liorations** :
- ‚úÖ **2 options visuellement distinctes** (bleu pour ZIP, vert pour CSV)
- ‚úÖ **Explications claires** pour chaque option
- ‚úÖ **Extensions accept√©es** affich√©es
- ‚úÖ **Avantages mis en avant** (skip OCR, faster, cheaper)

---

### 3. JavaScript - Double handler d'upload

**Fichier** : [app/templates/index.html](app/templates/index.html:421-474)

#### Handler ZIP (Option A)

```javascript
document.getElementById('uploadZipForm').addEventListener('submit', async (e) => {
  // ... upload vers /upload_zip
  if (res.ok) {
    currentPath = json.path;
    uploadResult.innerHTML = `‚úÖ ZIP uploaded: ${currentPath}
                               Next: Extract Text & Metadata (Step 2)`;
    document.getElementById('dataframe-section').style.display = 'block';
  }
});
```

**Flux** : ZIP ‚Üí Step 2 (Extract Text) ‚Üí Step 3 (Chunking) ‚Üí ...

#### Handler CSV (Option B)

```javascript
document.getElementById('uploadCsvForm').addEventListener('submit', async (e) => {
  // ... upload vers /upload_csv
  if (res.ok) {
    currentPath = json.path;
    uploadResult.innerHTML = `‚úÖ CSV ingested: ${currentPath}
                               ${json.message}
                               CSV processed! Next: Text Chunking (Step 3.1)`;
    // SKIP Step 2 (dataframe extraction) - already done in backend
    document.getElementById('dataframe-section').style.display = 'none';
    document.getElementById('initial-chunk-section').style.display = 'block';
  }
});
```

**Flux** : CSV ‚Üí **DIRECT** Step 3.1 (Chunking) ‚Üí Step 3.2 ‚Üí ...

**Diff√©rence cl√©** : CSV saute l'√©tape 2 (extraction OCR) car le texte est d√©j√† disponible.

---

## Flux utilisateur compar√©

### Option A : ZIP (Zotero + PDFs)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Upload ZIP Archive                  ‚îÇ
‚îÇ    - Zotero JSON + PDF files           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Extract Text & Metadata (OCR)       ‚îÇ
‚îÇ    - rad_dataframe.py                  ‚îÇ
‚îÇ    - Mistral/OpenAI OCR                ‚îÇ
‚îÇ    - Output: output.csv                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.1 Initial Text Chunking              ‚îÇ
‚îÇ     - rad_chunk.py --phase initial     ‚îÇ
‚îÇ     - GPT recodage (si non-Mistral)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.2 Dense Embeddings                   ‚îÇ
‚îÇ     - OpenAI embeddings                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.3 Sparse Embeddings                  ‚îÇ
‚îÇ     - spaCy TF lemmatis√©               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Upload to Vector DB                 ‚îÇ
‚îÇ    - Pinecone / Weaviate / Qdrant      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Temps estim√©** : 10-30 min (selon nombre de PDFs)
**Co√ªt API** : OCR + GPT recodage + embeddings

---

### Option B : CSV (Direct)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Upload CSV File                     ‚îÇ
‚îÇ    - CSV with text column              ‚îÇ
‚îÇ    - Backend: ingestion.csv_ingestion  ‚îÇ
‚îÇ    - Output: output.csv (auto)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
                 ‚è≠Ô∏è SKIP Step 2 (pas d'OCR)
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.1 Initial Text Chunking              ‚îÇ
‚îÇ     - rad_chunk.py --phase initial     ‚îÇ
‚îÇ     - ‚ùå PAS de GPT recodage (CSV)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.2 Dense Embeddings                   ‚îÇ
‚îÇ     - OpenAI embeddings                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3.3 Sparse Embeddings                  ‚îÇ
‚îÇ     - spaCy TF lemmatis√©               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Upload to Vector DB                 ‚îÇ
‚îÇ    - Pinecone / Weaviate / Qdrant      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Temps estim√©** : 3-10 min (selon nombre de lignes)
**Co√ªt API** : **Seulement embeddings** (80% d'√©conomie)

---

## Format CSV attendu

### Minimal (1 colonne)

```csv
text
"Mon premier document avec du texte."
"Un second document avec plus de contenu."
```

### Recommand√© (avec m√©tadonn√©es)

```csv
text,title,category,priority,date,author
"Introduction to NLP...","NLP Guide","Tech","High","2023-05-15","John"
"Data quality matters...","Data Quality","Science","Medium","2023-06-20","Jane"
```

**Colonnes automatiques ajout√©es** :
- `source_type`: "csv"
- `texteocr_provider`: "csv" (pour skip GPT recodage)
- `ingested_at`: timestamp ISO
- `row_index`: num√©ro de ligne (optionnel)

**Toutes les colonnes CSV** sont conserv√©es comme m√©tadonn√©es dans Pinecone/Weaviate/Qdrant !

---

## Tests de l'interface

### Test 1 : Upload CSV basique

1. D√©marrer le serveur :
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

2. Ouvrir http://localhost:8000

3. Dans "Option B: CSV File", s√©lectionner un CSV avec une colonne `text`

4. Cliquer "Upload CSV"

**Attendu** :
- Message : "‚úÖ CSV ingested: a1b2c3d4_my_documents"
- Message : "CSV ingested successfully: 10 rows processed."
- Section "3.1 Initial Text Chunking" appara√Æt
- Section "2. Extract Text & Metadata" reste cach√©e

### Test 2 : Upload ZIP (r√©gression)

1. Dans "Option A: ZIP Archive", s√©lectionner un ZIP Zotero

2. Cliquer "Upload ZIP"

**Attendu** :
- Message : "‚úÖ ZIP uploaded: a1b2c3d4_my_library"
- Section "2. Extract Text & Metadata" appara√Æt
- Workflow normal (OCR ‚Üí CSV ‚Üí chunking)

---

## Validation avec CSV de test

### Pr√©paration

```bash
# Cr√©er un CSV de test
cat > /tmp/test.csv << 'EOF'
text,title,category
"First document about AI.","AI Intro","Technology"
"Second document about data.","Data Guide","Science"
EOF
```

### Sc√©nario complet

1. **Upload CSV** via interface ‚Üí Option B
2. **Chunking** : Cliquer "Generate Chunks" (Step 3.1)
3. **Dense Embeddings** : Cliquer "Generate Dense Embeddings" (Step 3.2)
4. **Sparse Embeddings** : Cliquer "Generate Sparse Embeddings" (Step 3.3)
5. **Vectorisation** : Choisir "Pinecone", Index "test-csv", cliquer "Start Upload"

### V√©rification Pinecone

```python
from pinecone import Pinecone

pc = Pinecone(api_key="...")
index = pc.Index("test-csv")

# Query pour tester les m√©tadonn√©es
results = index.query(
    vector=[0.1]*3072,  # Dummy vector
    top_k=1,
    include_metadata=True
)

print(results['matches'][0]['metadata'])
# Attendu: {'title': 'AI Intro', 'category': 'Technology', 'source_type': 'csv', ...}
```

---

## Messages d'erreur possibles

| Erreur | Cause | Solution |
|--------|-------|----------|
| "Only .csv files are accepted." | Extension non-.csv | V√©rifier le fichier upload√© |
| "Failed to process CSV file." | CSV mal form√© | V√©rifier l'encodage (UTF-8 recommand√©) |
| "CSV ingestion module not found." | Module `ingestion` absent | V√©rifier que `core/` et `ingestion/` existent |
| "Colonne 'text' absente" | Pas de colonne `text` | Renommer la colonne principale en `text` |

---

## Configuration avanc√©e

### Modifier la colonne texte par d√©faut

Actuellement hardcod√© √† `"text"`. Pour changer :

**Option 1 : Backend** - Modifier [ingestion/csv_ingestion.py](ingestion/csv_ingestion.py)

```python
# Ligne ~50
class CSVIngestionConfig:
    def __init__(
        self,
        text_column: str = "description",  # ‚Üê Changer ici
        ...
    ):
```

**Option 2 : Interface** - Ajouter un champ "Text Column" dans le formulaire

```html
<!-- Dans app/templates/index.html -->
<form id="uploadCsvForm" ...>
  <label for="csvTextColumn">Text Column Name:</label>
  <input type="text" id="csvTextColumn" value="text" placeholder="text" />

  <input type="file" name="file" accept=".csv" required />
  <button type="submit">Upload CSV</button>
</form>
```

Puis modifier le JavaScript pour envoyer ce param√®tre au backend.

---

## D√©pannage

### CSV upload√© mais Step 3.1 ne s'affiche pas

**Cause** : Erreur JavaScript ou r√©ponse backend incorrecte

**Debug** :
1. Ouvrir la console navigateur (F12)
2. Chercher erreurs JavaScript
3. V√©rifier la r√©ponse de `/upload_csv` :
   ```javascript
   console.log(json);  // Dans le handler uploadCsvForm
   ```

### M√©tadonn√©es CSV manquantes dans Pinecone

**Cause** : Version non refactoris√©e de `rad_vectordb.py`

**V√©rification** :
```bash
grep -n "for key, value in chunk.items()" scripts/rad_vectordb.py
```

**Attendu** : Ligne 86 (Pinecone), 546 (Weaviate), 646 (Qdrant)

### Recodage GPT activ√© malgr√© CSV

**Cause** : `texteocr_provider` non d√©fini √† "csv"

**V√©rification** :
```bash
cat tests/fixtures/test_output.csv | head -1
# Doit contenir : texteocr_provider
```

---

## Prochaines am√©liorations

- [ ] Champ "Text Column" configurable dans l'interface
- [ ] Preview des colonnes CSV avant upload
- [ ] Support drag-and-drop pour upload
- [ ] Validation de sch√©ma CSV c√¥t√© frontend
- [ ] Estimation du co√ªt API avant traitement
- [ ] Support fichiers Excel (.xlsx)

---

## Ressources

- **Guide utilisateur CSV** : [CSV_INGESTION_GUIDE.md](CSV_INGESTION_GUIDE.md)
- **Architecture pipeline** : [pipeline_current_architecture.md](pipeline_current_architecture.md)
- **Code backend** : [app/main.py](app/main.py:143-215)
- **Code frontend** : [app/templates/index.html](app/templates/index.html:131-474)

---

**D√©velopp√© le** : 2025-10-21
**Par** : Claude + Amar Lakel
**Version RAGpy** : 2.1 (Multi-source web interface)
**Status** : ‚úÖ Production-ready
